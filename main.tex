\input{header.tex}
\begin{document}
\maketitle

\section{Introduction}

	\subsection{Contexte}

		\paragraph{}
		La nécessité de la simulation numérique est aujourd'hui bien admise, tant dans le monde industriel que le monde académique.
		Les entreprises comme les laboratoires de recherche ont besoin de pouvoir accéder à certaines grandeurs physiques associées à des phénomènes et à des régimes de fonctionnement qui ne sont pas possible de réaliser à notre échelle, la limitation pouvant être matérielle ou bien financière.
		On peut prendre comme exemple l'étude du givrage qui à lieu sur la voilure d'un avion, qui est réalisable expérimentalement mais représente un budget imposant pour l’avionneur, ou bien l'étude des transferts thermiques d'une capsule de rentrée atmosphérique, bien plus difficile à réaliser expérimentalement.
		Pour contourner ces limitations, la simulation numérique est la meilleure option, car elle permet de modéliser un tel cas d'étude par l’exécution d'un programme informatique, et d'obtenir un ensemble important de données qui seront analysées par la suite pour répondre aux questions souhaitées.

		\paragraph{}
		La simulation numérique n'est pas non plus un outil absolu ou parfait : si elle rend possible l'obtention de données inaccessible par l'expérimentation, elle nécessite cependant un travail de modélisation et de développement, des connaissances, et surtout un important travail de calcul informatique.
		Par travail on peut entendre ici une puissance de calcul multiplié par un temps de calcul : n'importe quelle machine ne peut pas réaliser n'importe quelle simulation, certains cas nécessitent des machines très puissantes, et même avec ces machines la simulation numérique n'est pas instantanée, et il est courant de lancer des calculs durant plusieurs semaines.
		Pour éviter de se retrouver avec des calculs qui s'exécuteraient trop longtemps sur des machines trop puissantes, ce qui coûterait trop cher, on va réaliser des choix pour optimiser l'efficacité du calcul.
		On va privilégier un type d'algorithme pour un type de calcul, choisir une mise en donnée plus adaptée qu'une autre pour notre architecture logicielle, ..., tout cela pour réduire le coût en temps et en puissance de calcul de notre simulation numérique.
		C'est pour pouvoir effectuer ces choix qu'il faut posséder des connaissances dans ce domaine.
		L'objectif de ma thèse est d'identifier et de comparer de tels choix qui vont rendre plus efficace la simulation de phénomènes physiques s'inscrivant dans un cadre donné : les problèmes stationnaires en énergétique et multi-physique.

		\paragraph{}
		Il est d'usage de séparer les problèmes de simulation numérique en deux grandes classes : les problèmes instationnaires qui vont décrire l'évolution d'un système au cours du temps, et les problèmes stationnaires qui cherchent la valeur d'un état convergé du même système.
		Cette distinction est déjà bien connue, et engendre déjà des différents choix dans la résolution des problèmes : un problème instationnaire aura un faible pas de temps pour bien capter l'évolution temporelle de chacune des physiques mises en jeu, et utilisera des méthodes d'intégration temporelles explicites, alors qu'un problème stationnaire permet une montée en CFL qui s'accompagne de l'utilisation de méthodes implicites.
		Ma thèse s'intéresse au second type : les problèmes stationnaires.


	\subsection{Le problème stationnaire}

		\paragraph{}
		On considère un problème type de simulation numérique en dynamique des fluides (CFD), qui consiste à résoudre sur un domaine spatial donné une ou un ensemble d'équations décrivant les lois d'évolution du modèle physique.
		Typiquement, on cherche à résoudre une équation aux dérivées partielles :
		$$\frac{\partial W}{\partial t} = \operatorname{f}\left(W\right)$$
		sur un domaine spatial $\mathcal{D}$.
		On note $W$ l'état du système en un point de l'espace.
		Pour un problème stationnaire, l'état du système n'évolue pas, et donc l'équation à résoudre devient :
		\begin{equation}\label{eq:f=0}
			\operatorname{f}\left(W\right) = 0
		\end{equation}
		Concrètement, $W$ représente les grandeurs physiques du système en un point de l'espace et $\operatorname{f}$ une fonction dépendant de l'état du système, mais pouvant également dépendre de ses dérivées spatiales.
		Puisqu'on cherche une solution stationnaire, on l'exprime comme un zéro de cette fonction.
		Pour obtenir cette solution, on introduit la notion de pseudo-temps\cite{KelleyKeyes1996}.
		Par exemple, pour résoudre les équations de Navier-Stokes, les dérivées spatiales d'ordre un et deux interviennent.

		\paragraph{}
		Résoudre l'évolution du système en fonction du temps depuis un état initial connu s'avère souvent plus coûteux que nécessaire, car les états intermédiaires ne nous intéressent pas.
		Inversement, utiliser un algorithme tel que la méthode de Newton de manière brute sur la fonction $\operatorname{f}$ n'aboutit pas.
		Le procédé de plus courant est donc  d'utiliser une méthode introduisant un pseudo-temps (Pseudo-transient continuation method).
		On cherche à résoudre l'équation (\ref{eq:f=0}), et on dispose d'un itéré initial $W_0$.
		On va chercher la solution comme étant la limite en $t = +\infty$ de
		\begin{equation}\label{eq:edp}
			\left\{\begin{aligned}
				\frac{\partial W}{\partial t}\left(t, x\right) = \operatorname{f}\left(W\right) \\
				W\left(t_0, x\right) = W_0\left(x\right)
			\end{aligned}\right.,\qquad \forall x\in\mathcal{D}
		\end{equation}
		La différence avec la résolution d'un problème instationnaire et que les états intermédiaires ne nous intéressent pas, et donc on peut se permettre de calculer des états non physiques, ou des transitions différentes du vrai système physique, du moment que l'état convergé est correct.


	\subsection{Discrétisation}

		\paragraph{}
		Lorsque l'on résout une équation aux dérivées partielles avec une méthode numérique, il est nécessaire de réaliser une discrétisation du problème, ne serait-ce que pour pouvoir représenter l'état du système dans tout le domaine dans un ordinateur.
		En pratique, on réalise deux niveaux de discrétisation : temporel et spatial.

		\paragraph{}
		La discrétisation spatiale consiste à diviser le domaine d'étude $\mathcal{D}$ en un ensemble de cellules qui forment un maillage.
		Les grandeurs physiques étudiées comme la vitesse du fluide, sa température, sa densité, ..., sont alors représentés dans chaque cellules, par leur valeur moyenne, ou leur valeur sur chaque interface, ou de manière plus complexe en fonction du choix de discrétisation pris par l'utilisateur.
		Sans rentrer dans les détails, puisque cette problématique de discrétisation spatiale ne rentre pas dans le cadre de ma thèse, l'état physique dans l'ensemble du domaine est représenté non plus par une fonction $W : \mathcal{D} \rightarrow \mathbb{R}^n$ mais par un vecteur $W \in \mathbb{R}^{N\times n}$, en notant $n$ le nombre de degrés de liberté et $N$ le nombre de cellules du maillage.
		La discrétisation spatiale donne également un moyen de calculer les dérivées spatiales de l'état en fonction de l'état.
		Ainsi l'équation aux dérivées partielles (\ref{eq:edp}) peut se réécrire comme une équation différentielle ordinaire :
		\begin{equation}\label{eq:edo}
			\left\{\begin{aligned}
				\frac{\mathrm{d} W}{\mathrm{d} t}\left(t\right) = f\left(W\right) \\
				W_0 \in \mathbb{R}^{N\times n}
			\end{aligned}\right.
		\end{equation}
		Puisque ma thèse ne s'intéresse pas à la discrétisation spatiale, nous nous placerons dans le cas général et chercherons à résoudre l'équation (\ref{eq:edo}).


		\paragraph{}
		La discrétisation temporelle permet de représenter le temps continu par une succession de temps discrets.
		On va donc représenter et calculer la solution non pas sur l'ensemble du temps mais en ces instants discrets.
		Concrètement, à l'instant $t_n$ on transforme l'équation aux dérivées partielles en relation de récurrence, entre l'état suivant à calculer $W_{n+1}$, l'état actuel $W_n$ et d'éventuels états précédents $W_i$.

		\paragraph{}
		Si on peut exprimer l'état suivant $W_{n+1}$ directement à partir de l'état courant (et éventuellement des précédents), la méthode d'intégration temporelle est dite explicite.
		L'intérêt d'une telle méthode est qu'elle permet de calculer l'état suivant très rapidement, souvent par la simple évaluation d'une fonction.
		Cependant, ces méthodes ont tendance à devenir instable dès que le nombre de Courant devient un peu grand (typiquement 1) et imposent donc l'utilisation de très faibles pas de temps.
		Puisque l'on cherche la solution au bout d'un temps long pour le problème stationnaire, l'utilisation de ces méthodes ne s'avère pas rentable : il vaut mieux payer plus cher l'itération mais converger plus rapidement, et c'est pour cela qu'on utilise les méthodes implicites.
		Elles se caractérisent par le fait que l'état suivant ne s'exprime pas explicitement à partir des états connus, mais qu'il est solution d'une équation, par exemple le zéro d'une fonction.



\section{Résolution implicite d'une Équation aux Dérivées Partielles}

	\subsection{Étapes}

		\paragraph{}
		Nous cherchons à résoudre l'équation (\ref{eq:edo}) en utilisant une méthode d'intégration implicite.
		Pour comprendre le fonctionnement des méthodes d'intégration temporelles implicites, on peut regarder la plus simple : la méthode d'Euler implicite.
		Elle consiste à intégrer entre $t_n$ et $t_{n+1}$ l'équation en gardant un second membre constant à $t = t_{n+1}$.
		Alors, en notant $\Delta t = t_{n+1} - t_n$ et $\Delta W = W_{n+1} - W_n$:
		$$\Delta W = \Delta t f\left(W_{n+1}\right)$$
		On voit que l'incrément de l'état $\Delta W$ peut s'exprimer comme le zéro d'une fonction : on cherche le zéro de $\delta W \mapsto \delta W - \Delta t f\left(W_n + \delta W\right)$.
		En notant $\operatorname{F}$ cette fonction, on obtient l'équation non-linéaire :
		\begin{equation}\label{eq:non_linear}
			\operatorname{F}\left(\delta W\right) = 0
		\end{equation}
		Nous allons donc devoir résoudre une équation non-linéaire à chaque itération.

		\paragraph{}
		Pour résoudre l'équation (\ref{eq:non_linear}), on utilise par exemple la méthode de Newton.
		On part d'une valeur initiale de l'incrément $\delta W_0 = 0$, mais on peut envisager de prendre d'autres valeurs, comme $\Delta t f\left(W_n\right)$ qui est l'incrément donné par la méthode d'Euler explicite.
		On va ensuite itérer pour trouver le zéro de $\operatorname{F}$.
		La linéarisation à l'ordre 1 de l'équation (\ref{eq:non_linear}) s'écrit :
		$$F(\delta W) = -\Delta t f\left(W_n\right) + \left(\mathrm{I} - \Delta t J_n\right)\delta W = 0$$
		où $J_n$ est la matrice jacobienne de $f$, et on exprime donc l'incrément comme étant la solution d'un système linéaire :
		\begin{equation}\label{eq:linear}
			A\delta W = b
		\end{equation}
		avec la matrice $A = \mathrm{I} - \Delta t J_n$ et le second membre $b = \Delta t f\left(W_n\right)$.
		A chaque étape de l'algorithme de Newton, il faut résoudre un système linéaire.

		\paragraph{}
		Pour toutes les méthodes d'intégration temporelles implicites, on retrouve la même idée : pour chaque itération on résout une équation non-linéaire (\ref{eq:non_linear}), en résolvant un ou plusieurs systèmes linéaires (\ref{eq:linear}).
		Les performances d'un code de calcul sont donc très étroitement liées à sa capacité à résoudre efficacement ces systèmes linéaires.



\section{Résolution du système linéaire}

	\paragraph{}
	On s'intéresse ici à la résolution numérique d'un système linéaire $Ax = b$, de taille $N$, c'est à dire que l'on cherche $x\in\mathbb{K}^N$ avec le second membre $b\in\mathbb{K}^N$ et la matrice $A\in\matrixsymb{N}{K}$ connus.
	Dans le cadre de l'énergétique et de la multi-physique, les équations sont réelles mais pour plus de généralité on prend le corps $\mathbb{K} = \mathbb{R}\textrm{ ou }\mathbb{C}$.

	\paragraph{}
	Il existe un grand nombre de méthodes pour inverser un problème linéaire.
	Cependant, en simulation numérique de la dynamique des fluides, la taille des maillage est souvent très importante (\PS{PAR EXEMPLE ?}), ce qui engendre des systèmes de très grande taille.
	Certaines méthodes de résolution ne sont alors plus compatibles, comme en particulier les méthodes directes.
	Cette famille de méthodes, dont fait partie par exemple la méthode du pivot de Gauss, calcule exactement la solution du système linéaire, mais nécessite un temps de calcul très important et un espace mémoire déraisonnable pour les tailles de nos problèmes.
	À l'inverse, les méthodes itératives produisent une suite de vecteurs qui convergent vers la solution du système linéaire.
	L'erreur sur la résolution du système décroît à mesure que l'algorithme itère et cela permet d'atteindre la précision souhaitée, non nulle mais suffisamment petite, pour un temps de calcul et une consommation mémoire maîtrisé.
	C'est l'idée que l'on retrouve sur la figure \ref{fig:direct-iterative} : la méthode directe ne fait aucun progrès avant $O\left(N^3\right)$ opérations, alors que la norme de l'erreur décroît pour la méthode itérative.

	\begin{figure}
		\centering
		\includegraphics[width=.8\textwidth]{images/direct-iterative.png}
		\caption{Convergence des méthodes directes et itératives, issu de \cite{TrefethenBau1997}}
		\label{fig:direct-iterative}
	\end{figure}


	\paragraph{}
	Comme cela a été mentionné, la taille des matrices rencontrées dans un problème typique de la simulation numérique de la dynamique des fluides est très grande.
	Les matrices ont également une autre propriété : la creusité.
	Puisque les matrices des systèmes linéaires à résoudre sont liées à une matrice jacobienne (voir équation (\ref{eq:linear})), un coefficient de la matrice symbolise une interaction entre deux points du maillage.
	On comprend alors que si le graphe de ces interactions dépend du schéma de discrétisation et d'intégration spatiale, deux points éloignés dans le maillage ne seront pas reliés.
	Ainsi, les matrices présentent cette caractéristique notable qu'est la creusité.
	En pratique, cela permettra d'utiliser des représentation astucieuses pour stocker les matrices en mémoire, telle que le format CSR (Compressed Sparse Row).
	Ces formats permettent à la fois d'économiser de l'espace en mémoire lors du stockage de la matrice, mais également de réaliser des opérations telles que le produit matrice vecteur plus efficacement.

Engleman fidap manuals

	\begin{figure}
		\centering
		\begin{subfigure}[t]{0.3\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/GT01R.png}
			\caption{GT01R - écoulement 2D non visqueux à travers un étage d'aubes de turbomachine}
			\label{fig:sparse.GT01R}
		\end{subfigure}
		\hfill
		\begin{subfigure}[t]{0.3\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/HV15R.png}
			\caption{HV15R - écoulement RANS 3D dans la soufflante d'un moteur}
			\label{fig:sparse.HV15R}
		\end{subfigure}
		\hfill
		\begin{subfigure}[t]{0.3\textwidth}
			\centering
			\includegraphics[width=\textwidth]{images/RM07R.png}
			\caption{RM07R - écoulement 3D visqueux dans le compresseur d'un turbopropulseur}
			\label{fig:sparse.RM07R}
		\end{subfigure}
		\caption{Représentation de matrices issues de problèmes de CFD, utilisant une méthode spatiale Volumes Finis\cite{PacullAubertBuisson2011}. Les points de couleurs correspondent à des valeurs non nulles, et les points blancs à des zéros.}
		\label{fig:sparse}
	\end{figure}


% 	\subsubsection{Matrice creuse}
%
% 		\paragraph{}
% 		Dans les problèmes de dynamique des fluides numérique, les matrices construites ont une caractéristique notable : elles sont creuses.
% 		Cela signifie qu'elles comportent beaucoup de zéros parmi leurs coefficients.
% 		Pour avoir une idée de l'origine de la creusité, on peut se dire que le coefficient $A_{i, j}$ correspond à l'interaction de la maille $i$ vers la maille $j$,
% 		et que donc seules les mailles "proches" de la maille $i$ vont avoir un coefficient non nul. Ainsi, les coefficients non nuls sont bien moins nombreux.
%
%
% 		\paragraph{}
% 		Par exemple, la matrice représentée sur la figure~\ref{fig:ex11} correspond à un problème de dynamique des fluides.
% 		Cette matrice provient de la base de donnée FIDAP de l'Université de Floride \footnote{\url{https://sparse.tamu.edu/FIDAP/ex11}}, et est utilisée comme exemple dans \cite{Pinel2010}.
% 		On observe sur la figure que la majorité de l'espace est blanc : c'est l'expression de la creusité sur cette représentation.
% 		Au contraire, les valeurs non nulles de la matrice sont concentrées sur la diagonale : c'est une caractéristique des problèmes de dynamique des fluides,
% 		car une zone du maillage est principalement affectée par les zones physiquement proches,
% 		et avec une numération naturelle des sommets on se retrouve avec des valeurs concentrées sur la diagonale.
%
% 		\paragraph{}
% 		Cette matrice est une matrice carrée de taille $N = 16,614$ avec $n_{nz} = 1,096,948$ entrées non nulles, soit un taux de remplissage de 0.40\%.
% 		Dans un tel cas, on voit qu'il serait déraisonnable de stocker entièrement la matrice, car 99,60\% de la mémoire ne servirait qu'à stocker des zéros.
% 		On va alors utiliser des méthodes de stockage de la matrice plus astucieuses \cite{Saad2003}, comme le format \emph{Compressed Sparse Row} (CSR).
% 		Avec ce format, plutôt que de stocker $N\times N = 276,024,996$ nombres pour représenter $A$, on va n'en stocker que $N + 2n_{nz} = 2,210,582$.
% 		Puisque les matrices que nous manipulons sont de très grande taille, il est nécessaire de porter attention à l'utilisation de la mémoire,
% 		et d'utiliser de telles représentations des matrices.
%
% \paragraph{}
% Il existe différents algorithmes pour résoudre un système linéaire. On les regroupe généralement en deux catégories :
% les algorithmes correspondants à des méthodes \emph{directes}, qui au bout d'un calcul plus ou moins long donnent une valeur de la solution,
% et ceux correspondants à des méthodes \emph{itératives}, qui construisent à chaque itération une valeur approchée de la solution, supposée converger vers la solution exacte.





	% \subsection{Méthodes Directes}
	%
	%  \paragraph{}
	%  Le premier type de méthodes de résolution d'un système linéaire regroupe les méthodes dites directes.
	%  Par exemple, on y retrouve l'élimination de Gauss, ou méthode du pivot de Gauss \cite{TrefethenBau1997}.
	%  Ces méthodes utilisent des décompositions astucieuses de la matrice à inverser pour se ramener à un système $Ty = c$ avec $T$ une matrice triangulaire.
	%  En effet l'inversion de ce système est immédiate.
	%  Ces méthodes, intuitives, sont souvent étudiées dans le cadre académique, et sont celles utilisées pour inverser "à la main" une matrice de faible taille.
	%
	%  \subsubsection{Méthode d'élimination de Gauss}
	% 		La méthode de Gauss équivaut à écrire la décomposition $A=LU$ où $L$ est triangulaire inférieure avec des coefficients diagonaux égaux à 1
	% 		et $U$ est triangulaire supérieure avec des coefficients diagonaux non nuls.
	% 		On résout ensuite $Ly = b$ puis $Ux = y$.
	% 		Cette méthode a une complexité algorithmique asymptotique en $O\left(N^3\right)$ pour une matrice de taille $N$.
	% 		De plus, elle ne présente aucun avantage dans le cas ou la matrice à inverser est creuse.
	%
	%  \subsubsection{Factorisation de Cholesky}
	% 	 Si $A$ est symétrique définie positive, il existe alors $L$ triangulaire inférieure, inversible, telle que $A=L\transpose{L}$.
	% 	 C'est un cas particulier de la méthode d'élimination de Gauss pour $U = \transpose{L}$.
	% 	 La méthode de Cholesky à un côut de $\frac{1}{3}N^3$.
	%
	%  \subsubsection{Méthode de Householder}
	% 	 Cette méthode utilise la décomposition $QR$ de la matrice :
	% 	 c'est une décomposition de la forme $A=QR$ où $Q$ est une matrice orthogonale $\transpose{Q}Q=I$, et $R$ une matrice triangulaire supérieure.
	% 	 On résout alors $Rx = \transpose{Q}b$.
	% 	 La méthode de Householder à un coût de $\frac{4}{3}N^3$.
	%
	%  \paragraph{}
	%  Il existe d'autres méthodes utilisant ces décompositions LU, de Cholesky ou QR de la matrice $A$, mais elles ont toutes le même inconvénient :
	%  elles sont beaucoup trop coûteuses pour des matrices de grande taille.
	%  Il est nécessaire d'aller jusqu'au bout de l'algorithme pour avoir la solution, et dans le cas ou la taille de la matrice est très grande,
	%  aller au bout de ces algorithmes est quelque chose qu'on ne peut pas se permettre.
	%  Pour pallier à ce problème, il faut se tourner vers les méthodes itératives.



	\paragraph{}
	Les méthodes itératives sont encore aujourd'hui très étudiées dans la communauté des mathématiques appliquées.



	Methodes iteratives\cite{OlshanskiiTyrtyshnikov2014, Saad2003}




\pagebreak
\bibliography{bibliography.bib}
\bibliographystyle{plain}

\end{document}
